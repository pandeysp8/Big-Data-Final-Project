{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import h5py\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"]='FALSE'\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from synrad_generator import get_synrad_train_generator,get_synrad_test_generator\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from .utils import SEVIRSequence\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import GeneratorEnqueuer\n",
    "\n",
    "#import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synrad_train_generator(sevir_catalog,\n",
    "                                sevir_location,\n",
    "                                batch_size=32,\n",
    "                                start_date=None,\n",
    "                                end_date=datetime.datetime(2019,6,1) ):\n",
    "    filt = lambda c:  c.pct_missing==0 # remove samples with missing data\n",
    "    return SEVIRSequence(catalog=sevir_catalog,\n",
    "                         sevir_data_home=sevir_location,\n",
    "                         x_img_types=['ir069','ir107','lght'],\n",
    "                         y_img_types=['vil'],\n",
    "                         batch_size=batch_size,\n",
    "                         start_date=start_date,\n",
    "                         end_date=end_date,\n",
    "                         catalog_filter=filt,\n",
    "                         unwrap_time=True)\n",
    "\n",
    "def get_synrad_test_generator(sevir_catalog,\n",
    "                               sevir_location,\n",
    "                               batch_size=32,\n",
    "                               start_date=datetime.datetime(2019,6,1),\n",
    "                               end_date=None):\n",
    "    filt = lambda c:  c.pct_missing==0 # remove samples with missing radar data\n",
    "    return SEVIRSequence(catalog=sevir_catalog,\n",
    "                         sevir_data_home=sevir_location,\n",
    "                         x_img_types=['ir069','ir107','lght'],\n",
    "                         y_img_types=['vil'],\n",
    "                         batch_size=batch_size,\n",
    "                         start_date=start_date,\n",
    "                         end_date=end_date,\n",
    "                         catalog_filter=filt,\n",
    "                         unwrap_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CATALOG = ('s3://bucket-satellite/CATALOG.csv')\n",
    "\n",
    "DATA_sevir = ('s3://bucket-satellite/data')\n",
    "\n",
    "DATA_interim = ('s3://bucket-satellite/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--sevir_data SEVIR_DATA]\n",
      "                             [--sevir_catalog SEVIR_CATALOG]\n",
      "                             [--output_location OUTPUT_LOCATION]\n",
      "                             [--n_chunks N_CHUNKS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Swati\\AppData\\Roaming\\jupyter\\runtime\\kernel-3bc62b0d-f036-4f9b-8982-3d87aedbb2de.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Make nowcast training & test datasets using SEVIR')\n",
    "parser.add_argument('--sevir_data', type=str, help='location of SEVIR dataset', default=DATA_CATALOG)\n",
    "parser.add_argument('--sevir_catalog', type=str, help='location of SEVIR dataset', default=DATA_sevir)\n",
    "parser.add_argument('--output_location', type=str, help='location of SEVIR dataset', default=DATA_interim)\n",
    "parser.add_argument('--n_chunks', type=int, help='Number of chucks to use (increase if memory limited)', default=20)\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_write_chunks( filename, generator, n_chunks ):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    chunksize = len(generator)//n_chunks\n",
    "    # get first chunk\n",
    "    logger.info('Gathering chunk 0/%s:' % n_chunks)\n",
    "    X,Y=generator.load_batches(n_batches=chunksize,offset=0,progress_bar=True)\n",
    "    # Create datasets\n",
    "    with h5py.File(filename, 'w') as hf:\n",
    "        hf.create_dataset(\"ir069\",  data=X[0], maxshape=(None,X[0].shape[1],X[0].shape[2],X[0].shape[3]))\n",
    "        hf.create_dataset(\"ir107\",  data=X[1], maxshape=(None,X[1].shape[1],X[1].shape[2],X[1].shape[3]))\n",
    "        hf.create_dataset(\"lght\",   data=X[2], maxshape=(None,X[2].shape[1],X[2].shape[2],X[2].shape[3]))\n",
    "        hf.create_dataset(\"vil\",    data=Y[0], maxshape=(None,Y[0].shape[1],Y[0].shape[2],Y[0].shape[3]))\n",
    "    # Gather other chunks\n",
    "    for c in range(1,n_chunks+1):\n",
    "        offset = c*chunksize\n",
    "        n_batches = min(chunksize,len(generator)-offset)\n",
    "        if n_batches<0: # all done\n",
    "            break\n",
    "        logger.info('Gathering chunk %d/%s:' % (c,n_chunks))\n",
    "        X,Y=generator.load_batches(n_batches=n_batches,offset=offset,progress_bar=True)\n",
    "        with h5py.File(filename, 'a') as hf:\n",
    "            hf[\"ir069\"].resize((hf[\"ir069\"].shape[0] + X[0].shape[0]), axis = 0)\n",
    "            hf[\"ir107\"].resize((hf[\"ir107\"].shape[0] + X[1].shape[0]), axis = 0)\n",
    "            hf[\"lght\"].resize((hf[\"lght\"].shape[0] + X[2].shape[0]), axis = 0)\n",
    "            hf[\"vil\"].resize((hf[\"vil\"].shape[0] + Y[0].shape[0]), axis = 0)\n",
    "\n",
    "            hf['ir069'][-X[0].shape[0]:]  = X[0]\n",
    "            hf['ir107'][-X[1].shape[0]:]  = X[1]\n",
    "            hf['lght'][-X[2].shape[0]:]   = X[2]\n",
    "            hf['vil'][-Y[0].shape[0]:]    = Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_TIMES = np.arange(-120.0,125.0,5) * 60 # in seconds\n",
    "\n",
    "# Record dtypes for reading\n",
    "DTYPES={'vil':np.uint8,'vis':np.int16,'ir069':np.int16,'ir107':np.int16,'lght':np.int16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEVIRSequence(Sequence):\n",
    "    \"\"\"\n",
    "    Sequence class for generating batches from SEVIR\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    catalog  str or pd.DataFrame\n",
    "        name of SEVIR catalog file to be read in, or an already read in and processed catalog\n",
    "    x_img_types  list \n",
    "        List of image types to be used as model inputs.  For types, run SEVIRSequence.get_types()\n",
    "    y_img_types  list or None\n",
    "       List of image types to be used as model targets (if None, __getitem__ returns only x_img_types )\n",
    "    sevir_data_home  str\n",
    "       Directory path to SEVIR data\n",
    "    catalog  str\n",
    "       Name of SEVIR catalog CSV file.  \n",
    "    batch_size  int\n",
    "       batch size to generate\n",
    "    n_batch_per_epoch  int or None\n",
    "       Number of batches in an epoch.  Set to None to match available data\n",
    "    start_date   datetime\n",
    "       Start time of SEVIR samples to generate   \n",
    "    end_date    datetime\n",
    "       End time of SEVIR samples to generate\n",
    "    datetime_filter   function\n",
    "       Mask function applied to time_utc column of catalog (return true to keep the row). \n",
    "       Pass function of the form   lambda t : COND(t)\n",
    "       Example:  lambda t: np.logical_and(t.dt.hour>=13,t.dt.hour<=21)  # Generate only day-time events\n",
    "    catalog_filter  function\n",
    "       Mask function applied to entire catalog dataframe (return true to keep row).  \n",
    "       Pass function of the form lambda catalog:  COND(catalog)\n",
    "       Example:  lambda c:  [s[0]=='S' for s in c.id]   # Generate only the 'S' events\n",
    "    unwrap_time   bool\n",
    "       If True, single images are returned instead of image sequences\n",
    "    shuffle  bool\n",
    "       If True, data samples are shuffled before each epoch\n",
    "    shuffle_seed   int\n",
    "       Seed to use for shuffling\n",
    "    output_type  np.dtype\n",
    "       dtype of generated tensors\n",
    "    normalize_x  list of tuple\n",
    "       list the same size as x_img_types containing tuples (scale,offset) used to \n",
    "       normalize data via   X  -->  (X-offset)*scale.  If None, no scaling is done\n",
    "    normalize_y  list of tuple\n",
    "       list the same size as y_img_types containing tuples (scale,offset) used to \n",
    "       normalize data via   X  -->  (X-offset)*scale\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    SEVIRSequence generator\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    \n",
    "        # Get just Radar image sequences\n",
    "        vil_seq = SEVIRSequence(x_img_types=['vil'],batch_size=16)\n",
    "        X = vil_seq.__getitem__(1234)  # returns list the same size as x_img_types passed to constructor\n",
    "        \n",
    "        # Get ir satellite+lightning as X,  radar for Y\n",
    "        vil_ir_lght_seq = SEVIRSequence(x_img_types=['ir107','lght'],y_img_types=['vil'],batch_size=4)\n",
    "        X,Y = vil_ir_lght_seq.__getitem__(420)  # X,Y are lists same length as x_img_types and y_img_types\n",
    "        \n",
    "        # Get single images of VIL\n",
    "        vil_imgs = SEVIRSequence(x_img_types=['vil'], batch_size=256, unwrap_time=True, shuffle=True)\n",
    "        \n",
    "        # Filter out some times\n",
    "        vis_seq = SEVIRSequence(x_img_types=['vis'],batch_size=32,unwrap_time=True,\n",
    "                                start_date=datetime.datetime(2018,1,1),\n",
    "                                end_date=datetime.datetime(2019,1,1),\n",
    "                                datetime_filter=lambda t: np.logical_and(t.dt.hour>=13,t.dt.hour<=21))\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 x_img_types=['vil'],\n",
    "                 y_img_types=None, \n",
    "                 catalog=DATA_CATALOG,\n",
    "                 batch_size = 3,\n",
    "                 n_batch_per_epoch=None,\n",
    "                 start_date=None,\n",
    "                 end_date=None,\n",
    "                 datetime_filter=None,\n",
    "                 catalog_filter=None,\n",
    "                 unwrap_time=False,\n",
    "                 sevir_data_home=DATA_sevir,\n",
    "                 shuffle=False,\n",
    "                 shuffle_seed=1,\n",
    "                 output_type=np.float32,\n",
    "                 normalize_x=None,\n",
    "                 normalize_y=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        self._samples = None\n",
    "        self._hdf_files = {}\n",
    "        self.x_img_types = x_img_types\n",
    "        self.y_img_types = y_img_types\n",
    "        if isinstance(catalog,(str,)):\n",
    "            self.catalog=pd.read_csv(catalog,parse_dates=['time_utc'],low_memory=False)\n",
    "        else:\n",
    "            self.catalog=catalog\n",
    "        self.batch_size=batch_size\n",
    "        self.n_batch_per_epoch = n_batch_per_epoch\n",
    "\n",
    "        self.datetime_filter=datetime_filter\n",
    "        self.catalog_filter=catalog_filter\n",
    "        self.start_date=start_date\n",
    "        self.end_date=end_date\n",
    "        self.unwrap_time = unwrap_time\n",
    "        self.sevir_data_home=sevir_data_home\n",
    "        self.shuffle=shuffle\n",
    "        self.shuffle_seed=int(shuffle_seed)\n",
    "        self.output_type=output_type\n",
    "        self.normalize_x = normalize_x\n",
    "        self.normalize_y = normalize_y\n",
    "        self.verbose=verbose\n",
    "        if normalize_x:\n",
    "            assert(len(normalize_x)==len(x_img_types))\n",
    "        if normalize_y:\n",
    "            assert(len(normalize_y)==len(y_img_types))\n",
    "\n",
    "        if self.start_date:\n",
    "            self.catalog = self.catalog[self.catalog.time_utc > self.start_date ]\n",
    "        if self.end_date:\n",
    "            self.catalog = self.catalog[self.catalog.time_utc <= self.end_date]\n",
    "        if self.datetime_filter:\n",
    "            self.catalog = self.catalog[self.datetime_filter(self.catalog.time_utc)]\n",
    "        \n",
    "        if self.catalog_filter:\n",
    "            self.catalog = self.catalog[self.catalog_filter(self.catalog)]\n",
    "        \n",
    "        self._compute_samples()\n",
    "        self._open_files(verbose=self.verbose)\n",
    "    \n",
    "    def load_batches(self,\n",
    "                     n_batches=10,\n",
    "                     offset=0,\n",
    "                     progress_bar=False):\n",
    "        \"\"\"\n",
    "        Loads a selected number of batches into memory.  This returns the concatenated\n",
    "        result of [self.__getitem__(i+offset) for i in range(n_batches)]\n",
    "\n",
    "        WARNING:  Be careful about running out of memory.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_batches   int\n",
    "            Number of batches to load.   Set to -1 to load them all, but becareful\n",
    "            not to run out of memory\n",
    "        offset int\n",
    "            batch offset to apply\n",
    "        progress_bar  bool\n",
    "            Show a progress bar during loading (requires tqdm module)\n",
    "\n",
    "        \"\"\"\n",
    "        if progress_bar:\n",
    "            try:\n",
    "                from tqdm import tqdm as RW\n",
    "            except ImportError:\n",
    "                print('You need to install tqdm to use progress bar')\n",
    "                RW=list\n",
    "        else:\n",
    "            RW=list\n",
    "        \n",
    "        n_batches = self.__len__() if n_batches==-1 else n_batches\n",
    "        n_batches = min(n_batches,self.__len__())\n",
    "        assert(n_batches>0)\n",
    "        \n",
    "        def out_shape(n_batches,shp,batch_size):\n",
    "            \"\"\"\n",
    "            Computes shape for preinitialization\n",
    "            \"\"\"\n",
    "            return (n_batches*batch_size,*shp)\n",
    "\n",
    "        bidx=0\n",
    "        if self.y_img_types is None: # one output\n",
    "            X = None\n",
    "            for i in RW( range(offset,offset+n_batches) ):\n",
    "                Xi = self.__getitem__(i)\n",
    "                if X is None:\n",
    "                    shps = [out_shape(n_batches,xi.shape[1:],xi.shape[0]) for xi in Xi] \n",
    "                    X = [np.empty( s,dtype=DTYPES[k] ) for s,k in zip(shps,self.x_img_types)]\n",
    "                for ii,xi in enumerate(Xi):\n",
    "                    X[ii][bidx:bidx+xi.shape[0]] = xi\n",
    "                bidx+=xi.shape[0]\n",
    "            return X\n",
    "        else:\n",
    "            X,Y=None,None\n",
    "            for i in RW( range(offset,offset+n_batches) ):\n",
    "                Xi,Yi = self.__getitem__(i)\n",
    "                if X is None:\n",
    "                    shps_x = [out_shape(n_batches,xi.shape[1:],xi.shape[0]) for xi in Xi]\n",
    "                    shps_y = [out_shape(n_batches,yi.shape[1:],yi.shape[0]) for yi in Yi]\n",
    "                    X = [np.empty(s,dtype=DTYPES[k]) for s,k in zip(shps_x,self.x_img_types)]\n",
    "                    Y = [np.empty(s,dtype=DTYPES[k]) for s,k in zip(shps_y,self.y_img_types)]\n",
    "                for ii,xi in enumerate(Xi):\n",
    "                    X[ii][bidx:bidx+xi.shape[0]] = xi\n",
    "                for ii,yi in enumerate(Yi):\n",
    "                    Y[ii][bidx:bidx+yi.shape[0]] = yi   \n",
    "                bidx+=xi.shape[0]\n",
    "            return X,Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self._samples.sample(frac=1,random_state=self.shuffle_seed)\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Closes all open file handles\n",
    "        \"\"\"\n",
    "        for f in self._hdf_files:\n",
    "            self._hdf_files[f].close()\n",
    "        self._hdf_files={}\n",
    "\n",
    "    def __del__(self):\n",
    "        for f,hf in self._hdf_files.items():\n",
    "            try:\n",
    "                hf.close()\n",
    "            except ImportError:\n",
    "                pass # okay when python shutting down\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        How many batches to generate per epoch\n",
    "        \"\"\"\n",
    "        if self._samples is not None:\n",
    "            # Use floor to avoid sending a batch of < self.batch_size in last batch.   \n",
    "            max_n = int(np.floor(self._samples.shape[0] / float(self.batch_size)))\n",
    "        else:\n",
    "            max_n = 0\n",
    "        if self.n_batch_per_epoch is not None:\n",
    "            return min(self.n_batch_per_epoch,max_n)\n",
    "        else:\n",
    "            return max_n\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "            resize(imread(file_name), (200, 200))\n",
    "               for file_name in batch_x]), np.array(batch_y)    \n",
    "        \"\"\"\n",
    "        batch = self._get_batch_samples(idx)\n",
    "        data = {}\n",
    "        for index, row in batch.iterrows():\n",
    "            data = self._read_data(row,data)\n",
    "        X = [data[t].astype(self.output_type) for t in self.x_img_types]\n",
    "        if self.normalize_x:\n",
    "            X = [SEVIRSequence.normalize(X[k],s) for k,s in enumerate(self.normalize_x)]\n",
    "\n",
    "        if self.y_img_types is not None:\n",
    "            Y = [data[t].astype(self.output_type) for t in self.y_img_types]\n",
    "            if self.normalize_y:\n",
    "                Y = [SEVIRSequence.normalize(Y[k],s) for k,s in enumerate(self.normalize_y)]\n",
    "            return X,Y\n",
    "        else:\n",
    "            return X    \n",
    "        \n",
    "    def _get_batch_samples(self,idx):\n",
    "        return self._samples.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "    \n",
    "    def _read_data(self,row,data):\n",
    "        \"\"\"\n",
    "        row is a series with fields IMGTYPE_filename, IMGTYPE_index, IMGTYPE_time_index\n",
    "        \"\"\"\n",
    "        imgtyps = np.unique([x.split('_')[0] for x in list(row.keys())])\n",
    "        for t in imgtyps:\n",
    "            fname = row[f'{t}_filename']\n",
    "            idx   = row[f'{t}_index']\n",
    "            #t_slice = row[f'{t}_time_index'] if self.unwrap_time else slice(0,None)\n",
    "            if self.unwrap_time:\n",
    "                tidx=row[f'{t}_time_index']\n",
    "                t_slice = slice(tidx,tidx+1) \n",
    "            else:\n",
    "                t_slice = slice(0,None)\n",
    "            # Need to bin lght counts into grid\n",
    "            if t=='lght':\n",
    "                lght_data = self._hdf_files[fname][idx][:]\n",
    "                data_i = self._lght_to_grid(lght_data,t_slice)\n",
    "            else:\n",
    "                data_i = self._hdf_files[fname][t][idx:idx+1,:,:,t_slice]\n",
    "            data[t] = np.concatenate( (data[t],data_i),axis=0 ) if (t in data) else data_i\n",
    "            \n",
    "        return data\n",
    "\n",
    "\n",
    "    def _lght_to_grid(self,data,t_slice=slice(0,None)):\n",
    "        \"\"\"\n",
    "        Converts Nx5 lightning data matrix into a 2D grid of pixel counts\n",
    "        \"\"\"\n",
    "        #out_size = (48,48,len(FRAME_TIMES)-1) if isinstance(t_slice,(slice,)) else (48,48)\n",
    "        out_size = (48,48,len(FRAME_TIMES)) if t_slice.stop is None else (48,48,1)\n",
    "        if data.shape[0]==0:\n",
    "            return np.zeros((1,)+out_size,dtype=np.float32)\n",
    "        \n",
    "        # filter out points outside the grid\n",
    "        x,y=data[:,3],data[:,4]\n",
    "        m=np.logical_and.reduce( [x>=0,x<out_size[0],y>=0,y<out_size[1]] )\n",
    "        data=data[m,:]\n",
    "        if data.shape[0]==0:\n",
    "            return np.zeros((1,)+out_size,dtype=np.float32)\n",
    "        \n",
    "        # Filter/separate times\n",
    "        t=data[:,0]\n",
    "        if t_slice.stop is not None:  # select only one time bin\n",
    "            if t_slice.stop>0:\n",
    "                if t_slice.stop < len(FRAME_TIMES):\n",
    "                    tm=np.logical_and( t>=FRAME_TIMES[t_slice.stop-1],\n",
    "                                       t< FRAME_TIMES[t_slice.stop] )\n",
    "                else:\n",
    "                    tm=t>=FRAME_TIMES[-1]\n",
    "            else: # special case:  frame 0 uses lght from frame 1\n",
    "                tm=np.logical_and( t>=FRAME_TIMES[0],t<FRAME_TIMES[1] )\n",
    "            #tm=np.logical_and( (t>=FRAME_TIMES[t_slice],t<FRAME_TIMES[t_slice+1]) )\n",
    "      \n",
    "            data=data[tm,:]\n",
    "            z=np.zeros( data.shape[0], dtype=np.int64 )\n",
    "        else: # compute z coodinate based on bin locaiton times\n",
    "            z=np.digitize(t,FRAME_TIMES)-1\n",
    "            z[z==-1]=0 # special case:  frame 0 uses lght from frame 1\n",
    "           \n",
    "        x=data[:,3].astype(np.int64)\n",
    "        y=data[:,4].astype(np.int64)\n",
    "        \n",
    "        k=np.ravel_multi_index(np.array([y,x,z]),out_size)\n",
    "        n = np.bincount(k,minlength=np.prod(out_size))\n",
    "        return np.reshape(n,out_size).astype(np.int16)[np.newaxis,:]\n",
    "         \n",
    "    \n",
    "    def _compute_samples(self):\n",
    "        \"\"\"\n",
    "        Computes the list of samples in catalog to be used. This sets\n",
    "           self._samples  \n",
    "\n",
    "        \"\"\"\n",
    "        # locate all events containing colocated x_img_types and y_img_types\n",
    "        imgt = self.x_img_types\n",
    "        if self.y_img_types:\n",
    "            imgt=list( set(imgt + self.y_img_types) ) # remove duplicates\n",
    "        imgts = set(imgt)            \n",
    "        filtcat = self.catalog[ np.logical_or.reduce([self.catalog.img_type==i for i in imgt]) ]\n",
    "        # remove rows missing one or more requested img_types\n",
    "        filtcat = filtcat.groupby('id').filter(lambda x: imgts.issubset(set(x['img_type'])))\n",
    "        # If there are repeated IDs, remove them (this is a bug in SEVIR)\n",
    "        filtcat = filtcat.groupby('id').filter(lambda x: x.shape[0]==len(imgt))\n",
    "        self._samples = filtcat.groupby('id').apply( lambda df: self._df_to_series(df,imgt) )\n",
    "        if self.shuffle:\n",
    "            self._samples=self._samples.sample(frac=1,random_state=self.shuffle_seed)\n",
    "        \n",
    "\n",
    "    def _df_to_series(self,df,imgt):\n",
    "        N_FRAMES=49  # TODO:  don't hardcode this\n",
    "        d = {}\n",
    "        df = df.set_index('img_type')\n",
    "        for i in imgt:\n",
    "            s = df.loc[i]\n",
    "            idx = s.file_index if i!='lght' else s.id \n",
    "            if self.unwrap_time:\n",
    "                d.update( {f'{i}_filename':[s.file_name]*N_FRAMES, \n",
    "                           f'{i}_index':[idx]*N_FRAMES,\n",
    "                           f'{i}_time_index':range(N_FRAMES)} )   \n",
    "            else:\n",
    "                d.update( {f'{i}_filename':[s.file_name], \n",
    "                           f'{i}_index':[idx]} )\n",
    "                   \n",
    "        return pd.DataFrame(d)\n",
    "\n",
    "    def _open_files(self,verbose=True):\n",
    "        \"\"\"\n",
    "        Opens HDF files\n",
    "        \"\"\"\n",
    "        imgt = self.x_img_types\n",
    "        if self.y_img_types:\n",
    "            imgt=list( set(imgt + self.y_img_types) ) # remove duplicates\n",
    "        hdf_filenames = []\n",
    "        for t in imgt:\n",
    "            hdf_filenames += list(np.unique( self._samples[f'{t}_filename'].values ))\n",
    "        self._hdf_files = {}\n",
    "        for f in hdf_filenames:\n",
    "            if verbose:\n",
    "                print('Opening HDF5 file for reading',f)\n",
    "            self._hdf_files[f] = h5py.File(self.sevir_data_home+'/'+f,'r')\n",
    "\n",
    "    def save(self,filename):\n",
    "        \"\"\"\n",
    "        Saves generator to a file for easier reloading\n",
    "        \"\"\"\n",
    "        self.close()\n",
    "        pickle.dump(open(filename,'wb'))\n",
    "        self._open_files(verbose=False)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        gen = pickle.load(open(filename,'rb'))\n",
    "        gen._open_files()\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_types():\n",
    "        return TYPES\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(X,s):\n",
    "        \"\"\"\n",
    "        Normalized data using s = (scale,offset) via Z = (X-offset)*scale\n",
    "        \"\"\"\n",
    "        return (X-s[1])*s[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def unnormalize(Z,s):\n",
    "        \"\"\"\n",
    "        Reverses the normalization performed in a SEVIRSequence generator\n",
    "        given s=(scale,offset)\n",
    "        \"\"\"\n",
    "        return Z/s[0]+s[1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\" \n",
    "    Runs data processing scripts to extract training set from SEVIR\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info('making final data set from raw data')\n",
    "    trn_generator = get_synrad_train_generator(sevir_catalog=args.sevir_catalog,\n",
    "                                               sevir_location=args.sevir_data)\n",
    "    tst_generator = get_synrad_test_generator(sevir_catalog=args.sevir_catalog,\n",
    "                                              sevir_location=args.sevir_data)\n",
    "    logger.info('Reading/writing training data to %s' % ('%s/synrad_training.h5' % args.output_location))\n",
    "    read_write_chunks('%s/synrad_training.h5' % args.output_location,trn_generator,args.n_chunks)\n",
    "    logger.info('Reading/writing testing data to %s' % ('%s/synrad_testing.h5' % args.output_location))\n",
    "    read_write_chunks('%s/synrad_testing.h5' % args.output_location,tst_generator,args.n_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Runs tests for nowcast model\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"]='FALSE'\n",
    "\n",
    "from tqdm import tqdm\n",
    "#from metrics import probability_of_detection,success_rate\n",
    "#from metrics.histogram import compute_histogram,score_histogram\n",
    "#from losses import lpips\n",
    "#from metrics import probability_of_detection,success_rate\n",
    "#from metrics.lpips_metric import get_lpips\n",
    "\n",
    "#from readers.nowcast_reader import get_data, read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file= \"../models/nowcast/mse_model.h5\"\n",
    "\n",
    "test_data_file = \"../data/nowcast_testing.h5\"\n",
    "\n",
    "output_csv_file = \"../data/synrad_test_output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "model_file      = args.model\n",
    "test_data_file  = args.test_data\n",
    "output_csv_file = args.output\n",
    "crop            = args.crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = {'scale':47.54,'shift':33.44}\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--test_data', type=str, default='mse',help='Test data .h5 file')\n",
    "    parser.add_argument('--model', type=str, help='Path to pretrained model to test or the string \"pers\" for the persistence model')\n",
    "    parser.add_argument('--output', type=str, help='Name of output .csv file',default='synrad_test_output.csv')  \n",
    "    parser.add_argument('--batch_size', type=int, help='batch size for testing', default=32)\n",
    "    parser.add_argument('--num_test', type=int, help='number of testing samples to use (None = all samples)', default=None)\n",
    "    parser.add_argument('--crop', type=int, help='crops this many pixels along edge before scoring', default=0)\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    return args\n",
    "#args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = {'scale':47.54,'shift':33.44}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(hits,\n",
    "                  misses,\n",
    "                  false_alarms,\n",
    "                  correct_rejections,\n",
    "                  partial_hits=0,\n",
    "                  partial_hit_weight=1.0,\n",
    "                  partial_misses=0,\n",
    "                  partial_miss_weight=0.0\n",
    "                  ):\n",
    "    \"\"\"\n",
    "    Computes scoring statistics based on hits (H), misses (M),\n",
    "    false alarms (F) and correct rejections (C).\n",
    "    \n",
    "    Optionally, partial hits and misses can also be passes, along with\n",
    "    weights for each.\n",
    "    \n",
    "    In the case of binary scoring (no partial hits/misses)\n",
    "    \n",
    "    stats = {'n_truth':H+M,\n",
    "             'n_pred':H+F,\n",
    "             'hits':H,\n",
    "             'misses':M,\n",
    "             'false_alarms':F,\n",
    "             'correct_rejections':C,\n",
    "             'pod':H/(H+M),\n",
    "             'far':F/(F+H),\n",
    "             'csi':H/(H+M+F),\n",
    "             'bias':(H+F)/(H+M)}\n",
    "    \n",
    "    If partial hits/misses are included, then  \n",
    "      \n",
    "        hits  :  hits   + partial_hits * partial_hit_weight\n",
    "        misses  :  misses + partial_misses * partial_miss_weight\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hits   scalar\n",
    "       Number of hits in scene   \n",
    "    misses   scalar\n",
    "       Number of misses in scene\n",
    "    false_alarms   scalar\n",
    "       Number of false alarms in scene\n",
    "    correct_rejections   scalar\n",
    "       Number of correct rejections in scene\n",
    "    partial_hits scalar\n",
    "       Number of partial hits\n",
    "    partial_hits_weight scalar\n",
    "       Weight of partial hits in pod/far/csi calculation\n",
    "    partial_misses\n",
    "       Number of partial misses\n",
    "    partial_missses_weight scalar\n",
    "       Weight of partial misses in pod/far/csi calculation\n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    scores  dict\n",
    "       Dictionary containing statistics                    \n",
    "    \"\"\"\n",
    "    H=hits+partial_hits*partial_hit_weight\n",
    "    M=misses+partial_misses*partial_miss_weight\n",
    "    F=false_alarms\n",
    "    C=correct_rejections\n",
    "    \n",
    "    n_truth=1.0*(H+M)\n",
    "    n_pred=1.0*(H+F)\n",
    "    n_any=1.0*(H+M+F)\n",
    "    \n",
    "    pod = 1.0*H/n_truth if n_truth>0 else 1.0\n",
    "    far = 1.0*F/n_pred if n_pred>0 else 0.0\n",
    "    csi = 1.0*H/n_any if n_any>0 else 1.0\n",
    "    bias = n_pred/n_truth if n_truth>0 else 1.0\n",
    "    \n",
    "    return {'n_truth':  n_truth,\n",
    "            'n_pred':  n_pred,\n",
    "            'hits':    H,\n",
    "            'misses':  M,\n",
    "            'false_alarms':F,\n",
    "            'correct_rejections':C,\n",
    "            'pod':pod,\n",
    "            'far':far,\n",
    "            'csi':csi,\n",
    "            'bias':bias}\n",
    "\n",
    "\n",
    "def compute_histogram(truth,pred,bins=255,**kwargs):\n",
    "    \"\"\"\n",
    "    Compares two np.array's of similar dimensions by computing a 2D histogram\n",
    "    over pixel values. This function is mainly a wrapper of numpy.histogram2d.\n",
    "    \n",
    "    The output is a matrix of counts.  The rows correspond to values (or bins)\n",
    "    in the turth, and the columns correspond to values (or \n",
    "    bins) in the prediction.  The value at pixel i,j in the output \n",
    "    matrix is the count of how many times a turth value falls in bin i \n",
    "    and a predicted value falls in bin j at co-located pixels.\n",
    "    \n",
    "    A \"perfect\" prediction would yield a hitograms with non-zero counts along \n",
    "    the diagonal and zero everywhere else. \n",
    "    \n",
    "    Standard forecast statistics can be computed quickly form the histogram\n",
    "    for multiple thresholds by passing output to score_histogram\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    truth np.array \n",
    "       Input array representing truth.  \n",
    "    pred np.array \n",
    "       Input array representing prediction\n",
    "    bins  (see numpy.histogram2d)\n",
    "       The bin specification.  Pasted form numpy docs: \n",
    "            If int, the number of bins for the two dimensions (nx=ny=bins).\n",
    "            If array_like, the bin edges for the two dimensions (x_edges=y_edges=bins).\n",
    "            If [int, int], the number of bins in each dimension (nx, ny = bins).\n",
    "            If [array, array], the bin edges in each dimension (x_edges, y_edges = bins).\n",
    "            A combination [int, array] or [array, int], where int is the number of bins and array is the bin edges.\n",
    "    kwargs  \n",
    "       Additional arguments passed to numpy.histogram2d.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    H    numpy array nx x ny\n",
    "       Histogram\n",
    "    rowedges   numpy array 1 x nx+1\n",
    "       Array of edges along rows\n",
    "    coledges   numpy array  1 x ny+1\n",
    "       Array of edges along columns\n",
    "    \n",
    "    \"\"\"\n",
    "    if pred.shape!=truth.shape:\n",
    "        raise ValueError('Inputs must have same dimension %s!=%s'%(pred.shape,truth.shape))\n",
    "    pred = pred.flatten()\n",
    "    truth = truth.flatten()\n",
    "    H,rowedges,coledges=np.histogram2d(truth,pred,bins=bins,**kwargs)\n",
    "    return H,rowedges,coledges\n",
    "    \n",
    "\n",
    "def score_histogram(hist, truth_bins, pred_bins, thresholds):\n",
    "    \"\"\"\n",
    "    Computes scoring statistics for multiple thresholds based on a histogram\n",
    "    (computing using compute_histogram).  \n",
    "    \n",
    "    It is assumed that the rows of the histogram correspond to values in the \n",
    "    prediction, and columns correspond to values in the truth.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hist  numpy array  nx x ny\n",
    "        Score histogram (from compute_histogram)\n",
    "    truth_bins  1 x nx+1        \n",
    "        Values corresponding to the rows of the histogram\n",
    "    pred_bins  1 x ny+1\n",
    "        Values corresponding to the columns of the histogram\n",
    "    thresholds   array or dict\n",
    "        If array, scoring thresholds used to compute statistics\n",
    "        If dict,  {label : threshold}.  labels are used as keys in output\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    scores   dict\n",
    "        Dictionary of scores for each threshold\n",
    "    \"\"\"\n",
    "    if type(thresholds)!=dict:\n",
    "        # Make it a dict\n",
    "        thresholds = {t:t for t in thresholds}\n",
    "    scores={}\n",
    "    for label,thres in thresholds.items():\n",
    "        thres_row=np.argmax(truth_bins>=thres)# argmax will give index of first 1\n",
    "        thres_col=np.argmax(pred_bins>=thres) # argmax will give index of first 1\n",
    "        H=np.sum(hist[thres_row:,thres_col:])\n",
    "        F=np.sum(hist[:thres_row,thres_col:])\n",
    "        M=np.sum(hist[thres_row:,:thres_col])\n",
    "        C=np.sum(hist[:thres_row,:thres_col])\n",
    "        scores[label]={'threshold':thres}\n",
    "        scores[label].update(compute_stats(H,M,F,C)) \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_scaled_tensor(imA):\n",
    "    # convert to RGB, scale images and cast to pytorch Tensor\n",
    "    # expected shape is Nx3xHxW\n",
    "    # first convet to fake RGB\n",
    "    imA = np.moveaxis(np.transpose(np.tile(np.expand_dims(imA,axis=-1), (1,1,1,3))),-1,0)\n",
    "    imA = 2*(imA - 127.5)/255 # conver to the range -1:1\n",
    "    return torch.FloatTensor(imA)\n",
    "\n",
    "def get_dist(model, yt, yp, n_out):\n",
    "    # this will take each time step, convert it to RGB, calculate the distance\n",
    "    d = np.zeros(n_out)\n",
    "    for ii in range(n_out):\n",
    "        truth = to_scaled_tensor(yt[...,ii])\n",
    "        pred = to_scaled_tensor(yp[...,ii])\n",
    "        d[ii] = model.forward(truth, pred).cpu().detach().numpy().mean()\n",
    "    # returns the average over the batch for each time step\n",
    "    return d\n",
    "\n",
    "def get_lpips(model, yp,yt,batch_size=32,n_out=12):    \n",
    "    d = np.zeros(n_out, dtype=np.float32)\n",
    "\n",
    "    #model = lpips.PerceptualLoss(model='net-lin', net='alex', use_gpu=True, gpu_ids=[0])\n",
    "\n",
    "    # do this in batches and average over all images\n",
    "    # inputs should Nx3xHxW\n",
    "    num_batches = 0\n",
    "    for ii in range(0, yt.shape[0], batch_size):\n",
    "        start = ii\n",
    "        stop = np.min([start+batch_size, yt.shape[0]])\n",
    "        d += get_dist(model, yp[start:stop,...], yt[start:stop,...], n_out)\n",
    "        num_batches += 1\n",
    "    d = d/num_batches\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_data, end=1024, pct_validation=0.2, dtype=np.float32):\n",
    "    # read data: this function returns scaled data\n",
    "    # what about shuffling ? \n",
    "    train_IN, train_OUT = read_data(train_data, end=end, dtype=dtype) \n",
    "    # Make the validation dataset the last pct_validation of the training data\n",
    "    val_idx = int((1-pct_validation)*train_IN.shape[0])\n",
    "    \n",
    "    val_IN = train_IN[val_idx:, ::]\n",
    "    train_IN = train_IN[:val_idx, ::]\n",
    "\n",
    "    val_OUT = train_OUT[val_idx:, ::]\n",
    "    train_OUT = train_OUT[:val_idx, ::]\n",
    "\n",
    "    return (train_IN,train_OUT,val_IN,val_OUT)\n",
    "\n",
    "\n",
    "def read_data(filename, rank=0, size=1, end=None, dtype=np.float32, MEAN=33.44, SCALE=47.54):\n",
    "    x_keys = ['IN']\n",
    "    y_keys = ['OUT']\n",
    "    s = np.s_[rank:end:size]\n",
    "    with h5py.File(filename, mode='r') as hf:\n",
    "        IN  = hf['IN'][s]\n",
    "        OUT = hf['OUT'][s]\n",
    "    IN = (IN.astype(dtype)-MEAN)/SCALE\n",
    "    OUT = (OUT.astype(dtype)-MEAN)/SCALE\n",
    "    return IN,OUT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of_detection(y_true,y_pred,threshold):\n",
    "    \"\"\"\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    y_true:     [N,L,L,D]\n",
    "    y_pred:     [N,L,L,D]\n",
    "    threshold:  [D,]\n",
    "    Outputs\n",
    "    -------\n",
    "    pod=hits/(hits+misses) averaged over the D channels\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(run_metric_over_channels(y_true,y_pred,threshold,_pod))\n",
    "\n",
    "def success_rate(y_true,y_pred,threshold):\n",
    "    \"\"\"\n",
    "    a.k.a    1 - (false alarm rate)\n",
    "    Inputs:\n",
    "    -------\n",
    "    y_true:     [N,L,L,D]\n",
    "    y_pred:     [N,L,L,D]\n",
    "    threshold:  [D,]\n",
    "    Outputs\n",
    "    -------\n",
    "    sucr=hits/(hits+false_alarms) averaged over the D channels\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(run_metric_over_channels(y_true,y_pred,threshold,_sucr))\n",
    "\n",
    "def critical_success_index(y_true,y_pred,threshold):\n",
    "    \"\"\"\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    y_true:     [N,L,L,D]\n",
    "    y_pred:     [N,L,L,D]\n",
    "    threshold:  [D,]\n",
    "    Outputs\n",
    "    -------\n",
    "    pod=hits/(hits+misses+false_alarms) averaged over the D channels\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(run_metric_over_channels(y_true,y_pred,threshold,_csi))\n",
    "\n",
    "def BIAS(y_true,y_pred,threshold):\n",
    "    \"\"\"\n",
    "    Computes the 2^( mean(log BIAS/log 2) )\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    y_true:     [N,L,L,D]\n",
    "    y_pred:     [N,L,L,D]\n",
    "    threshold:  [D,]\n",
    "    Outputs\n",
    "    -------\n",
    "    pod=(hits+false_alarms)/(hits+misses) pow(2)-log-averaged over the D channels\n",
    "    \"\"\"\n",
    "    logbias = tf.math.log(run_metric_over_channels(y_true,y_pred,threshold,_bias))/tf.math.log(2.0)\n",
    "    return tf.math.pow( 2.0, tf.reduce_mean(logbias))\n",
    "\n",
    "def run_metric_over_channels(y_true,y_pred,threshold,metric):\n",
    "    \"\"\"\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    y_true:     [N,L,L,D]\n",
    "    y_pred:     [N,L,L,D]\n",
    "    threshold:  [D,]\n",
    "    Outputs\n",
    "    -------\n",
    "    [D,] tensor of metrics computed over each channel\n",
    "    \"\"\"\n",
    "    # permute channels to first dim to work with tf.map_fn\n",
    "    elems = (tf.transpose(y_true,(3,0,1,2)),\n",
    "             tf.transpose(y_pred,(3,0,1,2)),\n",
    "             threshold)\n",
    "    # Average over channels\n",
    "    return tf.map_fn(metric,elems,dtype=tf.float32)\n",
    "\n",
    "\n",
    "def _pod(X):\n",
    "    \"\"\"\n",
    "    Single channel version of probability_of_detection\n",
    "    Inputs:\n",
    "    -------\n",
    "    tuple X = (y_true,y_pred,T) where\n",
    "                        y_true:     [N,L,L]\n",
    "                        y_pred:     [N,L,L]\n",
    "                        T:          [1,]\n",
    "    \"\"\"\n",
    "    y_true,y_pred,T=X\n",
    "    t,p=_threshold(y_true,y_pred,T)\n",
    "    hits = tf.reduce_sum(t*p)\n",
    "    misses = tf.reduce_sum( t*(1-p) )\n",
    "    return (hits+1e-6)/(hits+misses+1e-6)\n",
    "\n",
    "\n",
    "def _sucr(X):\n",
    "    \"\"\"\n",
    "    Single channel version of success_rate\n",
    "    Inputs:\n",
    "    -------\n",
    "    tuple X = (y_true,y_pred,T) where\n",
    "                        y_true:     [N,L,L]\n",
    "                        y_pred:     [N,L,L]\n",
    "                        T:          [1,]\n",
    "    \"\"\"\n",
    "    y_true,y_pred,T=X\n",
    "    t,p=_threshold(y_true,y_pred,T)\n",
    "    hits = tf.reduce_sum(t*p)\n",
    "    fas = tf.reduce_sum( (1-t)*p )\n",
    "    return (hits+1e-6)/(hits+fas+1e-6)\n",
    "\n",
    "def _csi(X):\n",
    "    \"\"\"\n",
    "    Single channel version of csi\n",
    "    Inputs:\n",
    "    -------\n",
    "    tuple X = (y_true,y_pred,T) where\n",
    "                        y_true:     [N,L,L]\n",
    "                        y_pred:     [N,L,L]\n",
    "                        T:          [1,]\n",
    "    \"\"\"\n",
    "    y_true,y_pred,T=X\n",
    "    t,p=_threshold(y_true,y_pred,T)\n",
    "    hits = tf.reduce_sum(t*p)\n",
    "    misses = tf.reduce_sum( t*(1-p) )\n",
    "    fas = tf.reduce_sum( (1-t)*p )\n",
    "    return (hits+1e-6)/(hits+misses+fas+1e-6)\n",
    "\n",
    "def _bias(X):\n",
    "    \"\"\"\n",
    "    Single channel version of csi\n",
    "    Inputs:\n",
    "    -------\n",
    "    tuple X = (y_true,y_pred,T) where\n",
    "                        y_true:     [N,L,L]\n",
    "                        y_pred:     [N,L,L]\n",
    "                        T:          [1,]\n",
    "    \"\"\"\n",
    "    y_true,y_pred,T=X\n",
    "    t,p=_threshold(y_true,y_pred,T)\n",
    "    hits = tf.reduce_sum(t*p)\n",
    "    misses = tf.reduce_sum( t*(1-p) )\n",
    "    fas = tf.reduce_sum( (1-t)*p )\n",
    "    return (hits+fas+1e-6)/(hits+misses+1e-6)\n",
    "\n",
    "def _threshold(X,Y,T):\n",
    "    \"\"\"\n",
    "    Returns binary tensors t,p the same shape as X & Y.  t = 1 whereever\n",
    "    X > t.  p =1 wherever Y > t.  p and t are set to 0 whereever EITHER\n",
    "    t or p are nan.   This is useful for counts that don't involve correct\n",
    "    rejections.\n",
    "    \"\"\"\n",
    "    t=tf.math.greater_equal(X, T)\n",
    "    t=tf.dtypes.cast(t, tf.float32)\n",
    "    p=tf.math.greater_equal(Y, T)\n",
    "    p=tf.dtypes.cast(p, tf.float32)\n",
    "    is_nan = tf.math.logical_or(tf.math.is_nan(X),tf.math.is_nan(Y))\n",
    "    t = tf.where(is_nan,tf.zeros_like(t,dtype=tf.float32),t)\n",
    "    p = tf.where(is_nan,tf.zeros_like(p,dtype=tf.float32),p)\n",
    "    return t,p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file= \"../models/nowcast/mse_model.h5\"\n",
    "\n",
    "test_data_file = \"../data/sample/nowcast_testing.h5\"\n",
    "\n",
    "output_csv_file = \"../data/synrad_test_output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from pdb import set_trace as st\n",
    "from IPython import embed\n",
    "\n",
    "class BaseModel():\n",
    "    def __init__(self):\n",
    "        pass;\n",
    "        \n",
    "    def name(self):\n",
    "        return 'BaseModel'\n",
    "\n",
    "    def initialize(self, use_gpu=True, gpu_ids=[0]):\n",
    "        self.use_gpu = use_gpu\n",
    "        self.gpu_ids = gpu_ids\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    def get_image_paths(self):\n",
    "        pass\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        pass\n",
    "\n",
    "    def get_current_visuals(self):\n",
    "        return self.input\n",
    "\n",
    "    def get_current_errors(self):\n",
    "        return {}\n",
    "\n",
    "    def save(self, label):\n",
    "        pass\n",
    "\n",
    "    # helper saving function that can be used by subclasses\n",
    "    def save_network(self, network, path, network_label, epoch_label):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        save_path = os.path.join(path, save_filename)\n",
    "        torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # helper loading function that can be used by subclasses\n",
    "    def load_network(self, network, network_label, epoch_label):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "        print('Loading network from %s'%save_path)\n",
    "        network.load_state_dict(torch.load(save_path))\n",
    "\n",
    "    def update_learning_rate():\n",
    "        pass\n",
    "\n",
    "    def get_image_paths(self):\n",
    "        return self.image_paths\n",
    "\n",
    "    def save_done(self, flag=False):\n",
    "        np.save(os.path.join(self.save_dir, 'done_flag'),flag)\n",
    "        np.savetxt(os.path.join(self.save_dir, 'done_flag'),[flag,],fmt='%i')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptualLoss(torch.nn.Module):\n",
    "    def __init__(self, model='net-lin', net='alex', colorspace='rgb', spatial=False, use_gpu=True, gpu_ids=[0], version='0.1'): # VGG using our perceptually-learned weights (LPIPS metric)\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        print('Setting up Perceptual loss...')\n",
    "        self.use_gpu = use_gpu\n",
    "        self.spatial = spatial\n",
    "        self.gpu_ids = gpu_ids\n",
    "        self.model = DistModel()\n",
    "        self.model.initialize(model=model, net=net, use_gpu=use_gpu, colorspace=colorspace, spatial=self.spatial, gpu_ids=gpu_ids, version=version)\n",
    "        print('...[%s] initialized'%self.model.name())\n",
    "        print('...Done')\n",
    "\n",
    "    def forward(self, pred, target, normalize=False):\n",
    "        \"\"\"\n",
    "        Pred and target are Variables.\n",
    "        If normalize is True, assumes the images are between [0,1] and then scales them between [-1,+1]\n",
    "        If normalize is False, assumes the images are already between [-1,+1]\n",
    "\n",
    "        Inputs pred and target are Nx3xHxW\n",
    "        Output pytorch Variable N long\n",
    "        \"\"\"\n",
    "\n",
    "        if normalize:\n",
    "            target = 2 * target  - 1\n",
    "            pred = 2 * pred  - 1\n",
    "\n",
    "        return self.model.forward(target, pred)\n",
    "\n",
    "def normalize_tensor(in_feat,eps=1e-10):\n",
    "    norm_factor = torch.sqrt(torch.sum(in_feat**2,dim=1,keepdim=True))\n",
    "    return in_feat/(norm_factor+eps)\n",
    "\n",
    "def l2(p0, p1, range=255.):\n",
    "    return .5*np.mean((p0 / range - p1 / range)**2)\n",
    "\n",
    "def psnr(p0, p1, peak=255.):\n",
    "    return 10*np.log10(peak**2/np.mean((1.*p0-1.*p1)**2))\n",
    "\n",
    "def dssim(p0, p1, range=255.):\n",
    "    return (1 - compare_ssim(p0, p1, data_range=range, multichannel=True)) / 2.\n",
    "\n",
    "def rgb2lab(in_img,mean_cent=False):\n",
    "    from skimage import color\n",
    "    img_lab = color.rgb2lab(in_img)\n",
    "    if(mean_cent):\n",
    "        img_lab[:,:,0] = img_lab[:,:,0]-50\n",
    "    return img_lab\n",
    "\n",
    "def tensor2np(tensor_obj):\n",
    "    # change dimension of a tensor object into a numpy array\n",
    "    return tensor_obj[0].cpu().float().numpy().transpose((1,2,0))\n",
    "\n",
    "def np2tensor(np_obj):\n",
    "     # change dimenion of np array into tensor array\n",
    "    return torch.Tensor(np_obj[:, :, :, np.newaxis].transpose((3, 2, 0, 1)))\n",
    "\n",
    "def tensor2tensorlab(image_tensor,to_norm=True,mc_only=False):\n",
    "    # image tensor to lab tensor\n",
    "    from skimage import color\n",
    "\n",
    "    img = tensor2im(image_tensor)\n",
    "    img_lab = color.rgb2lab(img)\n",
    "    if(mc_only):\n",
    "        img_lab[:,:,0] = img_lab[:,:,0]-50\n",
    "    if(to_norm and not mc_only):\n",
    "        img_lab[:,:,0] = img_lab[:,:,0]-50\n",
    "        img_lab = img_lab/100.\n",
    "\n",
    "    return np2tensor(img_lab)\n",
    "\n",
    "def tensorlab2tensor(lab_tensor,return_inbnd=False):\n",
    "    from skimage import color\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    lab = tensor2np(lab_tensor)*100.\n",
    "    lab[:,:,0] = lab[:,:,0]+50\n",
    "\n",
    "    rgb_back = 255.*np.clip(color.lab2rgb(lab.astype('float')),0,1)\n",
    "    if(return_inbnd):\n",
    "        # convert back to lab, see if we match\n",
    "        lab_back = color.rgb2lab(rgb_back.astype('uint8'))\n",
    "        mask = 1.*np.isclose(lab_back,lab,atol=2.)\n",
    "        mask = np2tensor(np.prod(mask,axis=2)[:,:,np.newaxis])\n",
    "        return (im2tensor(rgb_back),mask)\n",
    "    else:\n",
    "        return im2tensor(rgb_back)\n",
    "\n",
    "def rgb2lab(input):\n",
    "    from skimage import color\n",
    "    return color.rgb2lab(input / 255.)\n",
    "\n",
    "def tensor2im(image_tensor, imtype=np.uint8, cent=1., factor=255./2.):\n",
    "    image_numpy = image_tensor[0].cpu().float().numpy()\n",
    "    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + cent) * factor\n",
    "    return image_numpy.astype(imtype)\n",
    "\n",
    "def im2tensor(image, imtype=np.uint8, cent=1., factor=255./2.):\n",
    "    return torch.Tensor((image / factor - cent)\n",
    "                        [:, :, :, np.newaxis].transpose((3, 2, 0, 1)))\n",
    "\n",
    "def tensor2vec(vector_tensor):\n",
    "    return vector_tensor.data.cpu().numpy()[:, :, 0, 0]\n",
    "\n",
    "def voc_ap(rec, prec, use_07_metric=False):\n",
    "    \"\"\" ap = voc_ap(rec, prec, [use_07_metric])\n",
    "    Compute VOC AP given precision and recall.\n",
    "    If use_07_metric is true, uses the\n",
    "    VOC 07 11 point method (default:False).\n",
    "    \"\"\"\n",
    "    if use_07_metric:\n",
    "        # 11 point metric\n",
    "        ap = 0.\n",
    "        for t in np.arange(0., 1.1, 0.1):\n",
    "            if np.sum(rec >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(prec[rec >= t])\n",
    "            ap = ap + p / 11.\n",
    "    else:\n",
    "        # correct AP calculation\n",
    "        # first append sentinel values at the end\n",
    "        mrec = np.concatenate(([0.], rec, [1.]))\n",
    "        mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "        # compute the precision envelope\n",
    "        for i in range(mpre.size - 1, 0, -1):\n",
    "            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "        # to calculate area under PR curve, look for points\n",
    "        # where X axis (recall) changes value\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "        # and sum (\\Delta recall) * prec\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n",
    "\n",
    "def tensor2im(image_tensor, imtype=np.uint8, cent=1., factor=255./2.):\n",
    "# def tensor2im(image_tensor, imtype=np.uint8, cent=1., factor=1.):\n",
    "    image_numpy = image_tensor[0].cpu().float().numpy()\n",
    "    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + cent) * factor\n",
    "    return image_numpy.astype(imtype)\n",
    "\n",
    "def im2tensor(image, imtype=np.uint8, cent=1., factor=255./2.):\n",
    "# def im2tensor(image, imtype=np.uint8, cent=1., factor=1.):\n",
    "    return torch.Tensor((image / factor - cent)\n",
    "                        [:, :, :, np.newaxis].transpose((3, 2, 0, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import embed\n",
    "\n",
    "#from . import networks_basic as networks\n",
    "#from .__init__ import tensor2im,voc_ap\n",
    "\n",
    "class DistModel(BaseModel):\n",
    "    def name(self):\n",
    "        return self.model_name\n",
    "\n",
    "    def initialize(self, model='net-lin', net='alex', colorspace='Lab', pnet_rand=False, pnet_tune=False, model_path=None,\n",
    "            use_gpu=True, printNet=False, spatial=False, \n",
    "            is_train=False, lr=.0001, beta1=0.5, version='0.1', gpu_ids=[0]):\n",
    "        '''\n",
    "        INPUTS\n",
    "            model - ['net-lin'] for linearly calibrated network\n",
    "                    ['net'] for off-the-shelf network\n",
    "                    ['L2'] for L2 distance in Lab colorspace\n",
    "                    ['SSIM'] for ssim in RGB colorspace\n",
    "            net - ['squeeze','alex','vgg']\n",
    "            model_path - if None, will look in weights/[NET_NAME].pth\n",
    "            colorspace - ['Lab','RGB'] colorspace to use for L2 and SSIM\n",
    "            use_gpu - bool - whether or not to use a GPU\n",
    "            printNet - bool - whether or not to print network architecture out\n",
    "            spatial - bool - whether to output an array containing varying distances across spatial dimensions\n",
    "            spatial_shape - if given, output spatial shape. if None then spatial shape is determined automatically via spatial_factor (see below).\n",
    "            spatial_factor - if given, specifies upsampling factor relative to the largest spatial extent of a convolutional layer. if None then resized to size of input images.\n",
    "            spatial_order - spline order of filter for upsampling in spatial mode, by default 1 (bilinear).\n",
    "            is_train - bool - [True] for training mode\n",
    "            lr - float - initial learning rate\n",
    "            beta1 - float - initial momentum term for adam\n",
    "            version - 0.1 for latest, 0.0 was original (with a bug)\n",
    "            gpu_ids - int array - [0] by default, gpus to use\n",
    "        '''\n",
    "        BaseModel.initialize(self, use_gpu=use_gpu, gpu_ids=gpu_ids)\n",
    "\n",
    "        self.model = model\n",
    "        self.net = net\n",
    "        self.is_train = is_train\n",
    "        self.spatial = spatial\n",
    "        self.gpu_ids = gpu_ids\n",
    "        self.model_name = '%s [%s]'%(model,net)\n",
    "\n",
    "        if(self.model == 'net-lin'): # pretrained net + linear layer\n",
    "            self.net = PNetLin(pnet_rand=pnet_rand, pnet_tune=pnet_tune, pnet_type=net,\n",
    "                use_dropout=True, spatial=spatial, version=version, lpips=True)\n",
    "            kw = {}\n",
    "            if not use_gpu:\n",
    "                kw['map_location'] = 'cpu'\n",
    "            if(model_path is None):\n",
    "                import inspect\n",
    "                model_path = os.path.abspath(os.path.join(inspect.getfile(self.initialize), '..', 'weights/v%s/%s.pth'%(version,net)))\n",
    "\n",
    "            if(not is_train):\n",
    "                print('Loading model from: %s'%model_path)\n",
    "                self.net.load_state_dict(torch.load(model_path, **kw), strict=False)\n",
    "\n",
    "        elif(self.model=='net'): # pretrained network\n",
    "            self.net = networks.PNetLin(pnet_rand=pnet_rand, pnet_type=net, lpips=False)\n",
    "        elif(self.model in ['L2','l2']):\n",
    "            self.net = networks.L2(use_gpu=use_gpu,colorspace=colorspace) # not really a network, only for testing\n",
    "            self.model_name = 'L2'\n",
    "        elif(self.model in ['DSSIM','dssim','SSIM','ssim']):\n",
    "            self.net = networks.DSSIM(use_gpu=use_gpu,colorspace=colorspace)\n",
    "            self.model_name = 'SSIM'\n",
    "        else:\n",
    "            raise ValueError(\"Model [%s] not recognized.\" % self.model)\n",
    "\n",
    "        self.parameters = list(self.net.parameters())\n",
    "\n",
    "        if self.is_train: # training mode\n",
    "            # extra network on top to go from distances (d0,d1) => predicted human judgment (h*)\n",
    "            self.rankLoss = networks.BCERankingLoss()\n",
    "            self.parameters += list(self.rankLoss.net.parameters())\n",
    "            self.lr = lr\n",
    "            self.old_lr = lr\n",
    "            self.optimizer_net = torch.optim.Adam(self.parameters, lr=lr, betas=(beta1, 0.999))\n",
    "        else: # test mode\n",
    "            self.net.eval()\n",
    "\n",
    "        if(use_gpu):\n",
    "            self.net.to(gpu_ids[0])\n",
    "            self.net = torch.nn.DataParallel(self.net, device_ids=gpu_ids)\n",
    "            if(self.is_train):\n",
    "                self.rankLoss = self.rankLoss.to(device=gpu_ids[0]) # just put this on GPU0\n",
    "\n",
    "        if(printNet):\n",
    "            print('---------- Networks initialized -------------')\n",
    "            networks.print_network(self.net)\n",
    "            print('-----------------------------------------------')\n",
    "\n",
    "    def forward(self, in0, in1, retPerLayer=False):\n",
    "        ''' Function computes the distance between image patches in0 and in1\n",
    "        INPUTS\n",
    "            in0, in1 - torch.Tensor object of shape Nx3xXxY - image patch scaled to [-1,1]\n",
    "        OUTPUT\n",
    "            computed distances between in0 and in1\n",
    "        '''\n",
    "\n",
    "        return self.net.forward(in0, in1, retPerLayer=retPerLayer)\n",
    "\n",
    "    # ***** TRAINING FUNCTIONS *****\n",
    "    def optimize_parameters(self):\n",
    "        self.forward_train()\n",
    "        self.optimizer_net.zero_grad()\n",
    "        self.backward_train()\n",
    "        self.optimizer_net.step()\n",
    "        self.clamp_weights()\n",
    "\n",
    "    def clamp_weights(self):\n",
    "        for module in self.net.modules():\n",
    "            if(hasattr(module, 'weight') and module.kernel_size==(1,1)):\n",
    "                module.weight.data = torch.clamp(module.weight.data,min=0)\n",
    "\n",
    "    def set_input(self, data):\n",
    "        self.input_ref = data['ref']\n",
    "        self.input_p0 = data['p0']\n",
    "        self.input_p1 = data['p1']\n",
    "        self.input_judge = data['judge']\n",
    "\n",
    "        if(self.use_gpu):\n",
    "            self.input_ref = self.input_ref.to(device=self.gpu_ids[0])\n",
    "            self.input_p0 = self.input_p0.to(device=self.gpu_ids[0])\n",
    "            self.input_p1 = self.input_p1.to(device=self.gpu_ids[0])\n",
    "            self.input_judge = self.input_judge.to(device=self.gpu_ids[0])\n",
    "\n",
    "        self.var_ref = Variable(self.input_ref,requires_grad=True)\n",
    "        self.var_p0 = Variable(self.input_p0,requires_grad=True)\n",
    "        self.var_p1 = Variable(self.input_p1,requires_grad=True)\n",
    "\n",
    "    def forward_train(self): # run forward pass\n",
    "        # print(self.net.module.scaling_layer.shift)\n",
    "        # print(torch.norm(self.net.module.net.slice1[0].weight).item(), torch.norm(self.net.module.lin0.model[1].weight).item())\n",
    "\n",
    "        self.d0 = self.forward(self.var_ref, self.var_p0)\n",
    "        self.d1 = self.forward(self.var_ref, self.var_p1)\n",
    "        self.acc_r = self.compute_accuracy(self.d0,self.d1,self.input_judge)\n",
    "\n",
    "        self.var_judge = Variable(1.*self.input_judge).view(self.d0.size())\n",
    "\n",
    "        self.loss_total = self.rankLoss.forward(self.d0, self.d1, self.var_judge*2.-1.)\n",
    "\n",
    "        return self.loss_total\n",
    "\n",
    "    def backward_train(self):\n",
    "        torch.mean(self.loss_total).backward()\n",
    "\n",
    "    def compute_accuracy(self,d0,d1,judge):\n",
    "        ''' d0, d1 are Variables, judge is a Tensor '''\n",
    "        d1_lt_d0 = (d1<d0).cpu().data.numpy().flatten()\n",
    "        judge_per = judge.cpu().numpy().flatten()\n",
    "        return d1_lt_d0*judge_per + (1-d1_lt_d0)*(1-judge_per)\n",
    "\n",
    "    def get_current_errors(self):\n",
    "        retDict = OrderedDict([('loss_total', self.loss_total.data.cpu().numpy()),\n",
    "                            ('acc_r', self.acc_r)])\n",
    "\n",
    "        for key in retDict.keys():\n",
    "            retDict[key] = np.mean(retDict[key])\n",
    "\n",
    "        return retDict\n",
    "\n",
    "    def get_current_visuals(self):\n",
    "        zoom_factor = 256/self.var_ref.data.size()[2]\n",
    "\n",
    "        ref_img = tensor2im(self.var_ref.data)\n",
    "        p0_img = tensor2im(self.var_p0.data)\n",
    "        p1_img = tensor2im(self.var_p1.data)\n",
    "\n",
    "        ref_img_vis = zoom(ref_img,[zoom_factor, zoom_factor, 1],order=0)\n",
    "        p0_img_vis = zoom(p0_img,[zoom_factor, zoom_factor, 1],order=0)\n",
    "        p1_img_vis = zoom(p1_img,[zoom_factor, zoom_factor, 1],order=0)\n",
    "\n",
    "        return OrderedDict([('ref', ref_img_vis),\n",
    "                            ('p0', p0_img_vis),\n",
    "                            ('p1', p1_img_vis)])\n",
    "\n",
    "    def save(self, path, label):\n",
    "        if(self.use_gpu):\n",
    "            self.save_network(self.net.module, path, '', label)\n",
    "        else:\n",
    "            self.save_network(self.net, path, '', label)\n",
    "        self.save_network(self.rankLoss.net, path, 'rank', label)\n",
    "\n",
    "    def update_learning_rate(self,nepoch_decay):\n",
    "        lrd = self.lr / nepoch_decay\n",
    "        lr = self.old_lr - lrd\n",
    "\n",
    "        for param_group in self.optimizer_net.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        print('update lr [%s] decay: %f -> %f' % (type,self.old_lr, lr))\n",
    "        self.old_lr = lr\n",
    "\n",
    "def score_2afc_dataset(data_loader, func, name=''):\n",
    "    ''' Function computes Two Alternative Forced Choice (2AFC) score using\n",
    "        distance function 'func' in dataset 'data_loader'\n",
    "    INPUTS\n",
    "        data_loader - CustomDatasetDataLoader object - contains a TwoAFCDataset inside\n",
    "        func - callable distance function - calling d=func(in0,in1) should take 2\n",
    "            pytorch tensors with shape Nx3xXxY, and return numpy array of length N\n",
    "    OUTPUTS\n",
    "        [0] - 2AFC score in [0,1], fraction of time func agrees with human evaluators\n",
    "        [1] - dictionary with following elements\n",
    "            d0s,d1s - N arrays containing distances between reference patch to perturbed patches \n",
    "            gts - N array in [0,1], preferred patch selected by human evaluators\n",
    "                (closer to \"0\" for left patch p0, \"1\" for right patch p1,\n",
    "                \"0.6\" means 60pct people preferred right patch, 40pct preferred left)\n",
    "            scores - N array in [0,1], corresponding to what percentage function agreed with humans\n",
    "    CONSTS\n",
    "        N - number of test triplets in data_loader\n",
    "    '''\n",
    "\n",
    "    d0s = []\n",
    "    d1s = []\n",
    "    gts = []\n",
    "\n",
    "    for data in tqdm(data_loader.load_data(), desc=name):\n",
    "        d0s+=func(data['ref'],data['p0']).data.cpu().numpy().flatten().tolist()\n",
    "        d1s+=func(data['ref'],data['p1']).data.cpu().numpy().flatten().tolist()\n",
    "        gts+=data['judge'].cpu().numpy().flatten().tolist()\n",
    "\n",
    "    d0s = np.array(d0s)\n",
    "    d1s = np.array(d1s)\n",
    "    gts = np.array(gts)\n",
    "    scores = (d0s<d1s)*(1.-gts) + (d1s<d0s)*gts + (d1s==d0s)*.5\n",
    "\n",
    "    return(np.mean(scores), dict(d0s=d0s,d1s=d1s,gts=gts,scores=scores))\n",
    "\n",
    "def score_jnd_dataset(data_loader, func, name=''):\n",
    "    ''' Function computes JND score using distance function 'func' in dataset 'data_loader'\n",
    "    INPUTS\n",
    "        data_loader - CustomDatasetDataLoader object - contains a JNDDataset inside\n",
    "        func - callable distance function - calling d=func(in0,in1) should take 2\n",
    "            pytorch tensors with shape Nx3xXxY, and return pytorch array of length N\n",
    "    OUTPUTS\n",
    "        [0] - JND score in [0,1], mAP score (area under precision-recall curve)\n",
    "        [1] - dictionary with following elements\n",
    "            ds - N array containing distances between two patches shown to human evaluator\n",
    "            sames - N array containing fraction of people who thought the two patches were identical\n",
    "    CONSTS\n",
    "        N - number of test triplets in data_loader\n",
    "    '''\n",
    "\n",
    "    ds = []\n",
    "    gts = []\n",
    "\n",
    "    for data in tqdm(data_loader.load_data(), desc=name):\n",
    "        ds+=func(data['p0'],data['p1']).data.cpu().numpy().tolist()\n",
    "        gts+=data['same'].cpu().numpy().flatten().tolist()\n",
    "\n",
    "    sames = np.array(gts)\n",
    "    ds = np.array(ds)\n",
    "\n",
    "    sorted_inds = np.argsort(ds)\n",
    "    ds_sorted = ds[sorted_inds]\n",
    "    sames_sorted = sames[sorted_inds]\n",
    "\n",
    "    TPs = np.cumsum(sames_sorted)\n",
    "    FPs = np.cumsum(1-sames_sorted)\n",
    "    FNs = np.sum(sames_sorted)-TPs\n",
    "\n",
    "    precs = TPs/(TPs+FPs)\n",
    "    recs = TPs/(TPs+FNs)\n",
    "    score = voc_ap(recs,precs)\n",
    "\n",
    "    return(score, dict(ds=ds,sames=sames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class squeezenet(torch.nn.Module):\n",
    "    def __init__(self, requires_grad=False, pretrained=True):\n",
    "        super(squeezenet, self).__init__()\n",
    "        pretrained_features = tv.squeezenet1_1(pretrained=pretrained).features\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice2 = torch.nn.Sequential()\n",
    "        self.slice3 = torch.nn.Sequential()\n",
    "        self.slice4 = torch.nn.Sequential()\n",
    "        self.slice5 = torch.nn.Sequential()\n",
    "        self.slice6 = torch.nn.Sequential()\n",
    "        self.slice7 = torch.nn.Sequential()\n",
    "        self.N_slices = 7\n",
    "        for x in range(2):\n",
    "            self.slice1.add_module(str(x), pretrained_features[x])\n",
    "        for x in range(2,5):\n",
    "            self.slice2.add_module(str(x), pretrained_features[x])\n",
    "        for x in range(5, 8):\n",
    "            self.slice3.add_module(str(x), pretrained_features[x])\n",
    "        for x in range(8, 10):\n",
    "            self.slice4.add_module(str(x), pretrained_features[x])\n",
    "        for x in range(10, 11):\n",
    "            self.slice5.add_module(str(x), pretrained_features[x])\n",
    "        for x in range(11, 12):\n",
    "            self.slice6.add_module(str(x), pretrained_features[x])\n",
    "        for x in range(12, 13):\n",
    "            self.slice7.add_module(str(x), pretrained_features[x])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        h = self.slice1(X)\n",
    "        h_relu1 = h\n",
    "        h = self.slice2(h)\n",
    "        h_relu2 = h\n",
    "        h = self.slice3(h)\n",
    "        h_relu3 = h\n",
    "        h = self.slice4(h)\n",
    "        h_relu4 = h\n",
    "        h = self.slice5(h)\n",
    "        h_relu5 = h\n",
    "        h = self.slice6(h)\n",
    "        h_relu6 = h\n",
    "        h = self.slice7(h)\n",
    "        h_relu7 = h\n",
    "        vgg_outputs = namedtuple(\"SqueezeOutputs\", ['relu1','relu2','relu3','relu4','relu5','relu6','relu7'])\n",
    "        out = vgg_outputs(h_relu1,h_relu2,h_relu3,h_relu4,h_relu5,h_relu6,h_relu7)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class alexnet(torch.nn.Module):\n",
    "    def __init__(self, requires_grad=False, pretrained=True):\n",
    "        super(alexnet, self).__init__()\n",
    "        alexnet_pretrained_features = tv.alexnet(pretrained=pretrained).features\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice2 = torch.nn.Sequential()\n",
    "        self.slice3 = torch.nn.Sequential()\n",
    "        self.slice4 = torch.nn.Sequential()\n",
    "        self.slice5 = torch.nn.Sequential()\n",
    "        self.N_slices = 5\n",
    "        for x in range(2):\n",
    "            self.slice1.add_module(str(x), alexnet_pretrained_features[x])\n",
    "        for x in range(2, 5):\n",
    "            self.slice2.add_module(str(x), alexnet_pretrained_features[x])\n",
    "        for x in range(5, 8):\n",
    "            self.slice3.add_module(str(x), alexnet_pretrained_features[x])\n",
    "        for x in range(8, 10):\n",
    "            self.slice4.add_module(str(x), alexnet_pretrained_features[x])\n",
    "        for x in range(10, 12):\n",
    "            self.slice5.add_module(str(x), alexnet_pretrained_features[x])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        h = self.slice1(X)\n",
    "        h_relu1 = h\n",
    "        h = self.slice2(h)\n",
    "        h_relu2 = h\n",
    "        h = self.slice3(h)\n",
    "        h_relu3 = h\n",
    "        h = self.slice4(h)\n",
    "        h_relu4 = h\n",
    "        h = self.slice5(h)\n",
    "        h_relu5 = h\n",
    "        alexnet_outputs = namedtuple(\"AlexnetOutputs\", ['relu1', 'relu2', 'relu3', 'relu4', 'relu5'])\n",
    "        out = alexnet_outputs(h_relu1, h_relu2, h_relu3, h_relu4, h_relu5)\n",
    "\n",
    "        return out\n",
    "\n",
    "class vgg16(torch.nn.Module):\n",
    "    def __init__(self, requires_grad=False, pretrained=True):\n",
    "        super(vgg16, self).__init__()\n",
    "        vgg_pretrained_features = tv.vgg16(pretrained=pretrained).features\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice2 = torch.nn.Sequential()\n",
    "        self.slice3 = torch.nn.Sequential()\n",
    "        self.slice4 = torch.nn.Sequential()\n",
    "        self.slice5 = torch.nn.Sequential()\n",
    "        self.N_slices = 5\n",
    "        for x in range(4):\n",
    "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(4, 9):\n",
    "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(9, 16):\n",
    "            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(16, 23):\n",
    "            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(23, 30):\n",
    "            self.slice5.add_module(str(x), vgg_pretrained_features[x])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        h = self.slice1(X)\n",
    "        h_relu1_2 = h\n",
    "        h = self.slice2(h)\n",
    "        h_relu2_2 = h\n",
    "        h = self.slice3(h)\n",
    "        h_relu3_3 = h\n",
    "        h = self.slice4(h)\n",
    "        h_relu4_3 = h\n",
    "        h = self.slice5(h)\n",
    "        h_relu5_3 = h\n",
    "        vgg_outputs = namedtuple(\"VggOutputs\", ['relu1_2', 'relu2_2', 'relu3_3', 'relu4_3', 'relu5_3'])\n",
    "        out = vgg_outputs(h_relu1_2, h_relu2_2, h_relu3_3, h_relu4_3, h_relu5_3)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class resnet(torch.nn.Module):\n",
    "    def __init__(self, requires_grad=False, pretrained=True, num=18):\n",
    "        super(resnet, self).__init__()\n",
    "        if(num==18):\n",
    "            self.net = tv.resnet18(pretrained=pretrained)\n",
    "        elif(num==34):\n",
    "            self.net = tv.resnet34(pretrained=pretrained)\n",
    "        elif(num==50):\n",
    "            self.net = tv.resnet50(pretrained=pretrained)\n",
    "        elif(num==101):\n",
    "            self.net = tv.resnet101(pretrained=pretrained)\n",
    "        elif(num==152):\n",
    "            self.net = tv.resnet152(pretrained=pretrained)\n",
    "        self.N_slices = 5\n",
    "\n",
    "        self.conv1 = self.net.conv1\n",
    "        self.bn1 = self.net.bn1\n",
    "        self.relu = self.net.relu\n",
    "        self.maxpool = self.net.maxpool\n",
    "        self.layer1 = self.net.layer1\n",
    "        self.layer2 = self.net.layer2\n",
    "        self.layer3 = self.net.layer3\n",
    "        self.layer4 = self.net.layer4\n",
    "\n",
    "    def forward(self, X):\n",
    "        h = self.conv1(X)\n",
    "        h = self.bn1(h)\n",
    "        h = self.relu(h)\n",
    "        h_relu1 = h\n",
    "        h = self.maxpool(h)\n",
    "        h = self.layer1(h)\n",
    "        h_conv2 = h\n",
    "        h = self.layer2(h)\n",
    "        h_conv3 = h\n",
    "        h = self.layer3(h)\n",
    "        h_conv4 = h\n",
    "        h = self.layer4(h)\n",
    "        h_conv5 = h\n",
    "\n",
    "        outputs = namedtuple(\"Outputs\", ['relu1','conv2','conv3','conv4','conv5'])\n",
    "        out = outputs(h_relu1, h_conv2, h_conv3, h_conv4, h_conv5)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_average(in_tens, keepdim=True):\n",
    "    return in_tens.mean([2,3],keepdim=keepdim)\n",
    "\n",
    "def upsample(in_tens, out_H=64): # assumes scale factor is same for H and W\n",
    "    in_H = in_tens.shape[2]\n",
    "    scale_factor = 1.*out_H/in_H\n",
    "\n",
    "    return nn.Upsample(scale_factor=scale_factor, mode='bilinear', align_corners=False)(in_tens)\n",
    "\n",
    "\n",
    "class PNetLin(nn.Module):\n",
    "    def __init__(self, pnet_type='vgg', pnet_rand=False, pnet_tune=False, use_dropout=True, spatial=False, version='0.1', lpips=True):\n",
    "        super(PNetLin, self).__init__()\n",
    "\n",
    "        self.pnet_type = pnet_type\n",
    "        self.pnet_tune = pnet_tune\n",
    "        self.pnet_rand = pnet_rand\n",
    "        self.spatial = spatial\n",
    "        self.lpips = lpips\n",
    "        self.version = version\n",
    "        self.scaling_layer = ScalingLayer()\n",
    "\n",
    "        if(self.pnet_type in ['vgg','vgg16']):\n",
    "            net_type = vgg16\n",
    "            self.chns = [64,128,256,512,512]\n",
    "        elif(self.pnet_type=='alex'):\n",
    "            net_type = alexnet\n",
    "            self.chns = [64,192,384,256,256]\n",
    "        elif(self.pnet_type=='squeeze'):\n",
    "            net_type = squeezenet\n",
    "            self.chns = [64,128,256,384,384,512,512]\n",
    "        self.L = len(self.chns)\n",
    "\n",
    "        self.net = net_type(pretrained=not self.pnet_rand, requires_grad=self.pnet_tune)\n",
    "\n",
    "        if(lpips):\n",
    "            self.lin0 = NetLinLayer(self.chns[0], use_dropout=use_dropout)\n",
    "            self.lin1 = NetLinLayer(self.chns[1], use_dropout=use_dropout)\n",
    "            self.lin2 = NetLinLayer(self.chns[2], use_dropout=use_dropout)\n",
    "            self.lin3 = NetLinLayer(self.chns[3], use_dropout=use_dropout)\n",
    "            self.lin4 = NetLinLayer(self.chns[4], use_dropout=use_dropout)\n",
    "            self.lins = [self.lin0,self.lin1,self.lin2,self.lin3,self.lin4]\n",
    "            if(self.pnet_type=='squeeze'): # 7 layers for squeezenet\n",
    "                self.lin5 = NetLinLayer(self.chns[5], use_dropout=use_dropout)\n",
    "                self.lin6 = NetLinLayer(self.chns[6], use_dropout=use_dropout)\n",
    "                self.lins+=[self.lin5,self.lin6]\n",
    "\n",
    "    def forward(self, in0, in1, retPerLayer=False):\n",
    "        # v0.0 - original release had a bug, where input was not scaled\n",
    "        in0_input, in1_input = (self.scaling_layer(in0), self.scaling_layer(in1)) if self.version=='0.1' else (in0, in1)\n",
    "        outs0, outs1 = self.net.forward(in0_input), self.net.forward(in1_input)\n",
    "        feats0, feats1, diffs = {}, {}, {}\n",
    "\n",
    "        for kk in range(self.L):\n",
    "            feats0[kk], feats1[kk] = normalize_tensor(outs0[kk]), normalize_tensor(outs1[kk])\n",
    "            diffs[kk] = (feats0[kk]-feats1[kk])**2\n",
    "\n",
    "        if(self.lpips):\n",
    "            if(self.spatial):\n",
    "                res = [upsample(self.lins[kk].model(diffs[kk]), out_H=in0.shape[2]) for kk in range(self.L)]\n",
    "            else:\n",
    "                res = [spatial_average(self.lins[kk].model(diffs[kk]), keepdim=True) for kk in range(self.L)]\n",
    "        else:\n",
    "            if(self.spatial):\n",
    "                res = [upsample(diffs[kk].sum(dim=1,keepdim=True), out_H=in0.shape[2]) for kk in range(self.L)]\n",
    "            else:\n",
    "                res = [spatial_average(diffs[kk].sum(dim=1,keepdim=True), keepdim=True) for kk in range(self.L)]\n",
    "\n",
    "        val = res[0]\n",
    "        for l in range(1,self.L):\n",
    "            val += res[l]\n",
    "        \n",
    "        if(retPerLayer):\n",
    "            return (val, res)\n",
    "        else:\n",
    "            return val\n",
    "\n",
    "class ScalingLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScalingLayer, self).__init__()\n",
    "        self.register_buffer('shift', torch.Tensor([-.030,-.088,-.188])[None,:,None,None])\n",
    "        self.register_buffer('scale', torch.Tensor([.458,.448,.450])[None,:,None,None])\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return (inp - self.shift) / self.scale\n",
    "\n",
    "\n",
    "class NetLinLayer(nn.Module):\n",
    "    ''' A single linear layer which does a 1x1 conv '''\n",
    "    def __init__(self, chn_in, chn_out=1, use_dropout=False):\n",
    "        super(NetLinLayer, self).__init__()\n",
    "\n",
    "        layers = [nn.Dropout(),] if(use_dropout) else []\n",
    "        layers += [nn.Conv2d(chn_in, chn_out, 1, stride=1, padding=0, bias=False),]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class Dist2LogitLayer(nn.Module):\n",
    "    ''' takes 2 distances, puts through fc layers, spits out value between [0,1] (if use_sigmoid is True) '''\n",
    "    def __init__(self, chn_mid=32, use_sigmoid=True):\n",
    "        super(Dist2LogitLayer, self).__init__()\n",
    "\n",
    "        layers = [nn.Conv2d(5, chn_mid, 1, stride=1, padding=0, bias=True),]\n",
    "        layers += [nn.LeakyReLU(0.2,True),]\n",
    "        layers += [nn.Conv2d(chn_mid, chn_mid, 1, stride=1, padding=0, bias=True),]\n",
    "        layers += [nn.LeakyReLU(0.2,True),]\n",
    "        layers += [nn.Conv2d(chn_mid, 1, 1, stride=1, padding=0, bias=True),]\n",
    "        if(use_sigmoid):\n",
    "            layers += [nn.Sigmoid(),]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,d0,d1,eps=0.1):\n",
    "        return self.model.forward(torch.cat((d0,d1,d0-d1,d0/(d1+eps),d1/(d0+eps)),dim=1))\n",
    "\n",
    "class BCERankingLoss(nn.Module):\n",
    "    def __init__(self, chn_mid=32):\n",
    "        super(BCERankingLoss, self).__init__()\n",
    "        self.net = Dist2LogitLayer(chn_mid=chn_mid)\n",
    "        # self.parameters = list(self.net.parameters())\n",
    "        self.loss = torch.nn.BCELoss()\n",
    "\n",
    "    def forward(self, d0, d1, judge):\n",
    "        per = (judge+1.)/2.\n",
    "        self.logit = self.net.forward(d0,d1)\n",
    "        return self.loss(self.logit, per)\n",
    "\n",
    "# L2, DSSIM metrics\n",
    "class FakeNet(nn.Module):\n",
    "    def __init__(self, use_gpu=True, colorspace='Lab'):\n",
    "        super(FakeNet, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "        self.colorspace=colorspace\n",
    "\n",
    "class L2(FakeNet):\n",
    "\n",
    "    def forward(self, in0, in1, retPerLayer=None):\n",
    "        assert(in0.size()[0]==1) # currently only supports batchSize 1\n",
    "\n",
    "        if(self.colorspace=='RGB'):\n",
    "            (N,C,X,Y) = in0.size()\n",
    "            value = torch.mean(torch.mean(torch.mean((in0-in1)**2,dim=1).view(N,1,X,Y),dim=2).view(N,1,1,Y),dim=3).view(N)\n",
    "            return value\n",
    "        elif(self.colorspace=='Lab'):\n",
    "            value = l2(tensor2np(tensor2tensorlab(in0.data,to_norm=False)), \n",
    "                tensor2np(tensor2tensorlab(in1.data,to_norm=False)), range=100.).astype('float')\n",
    "            ret_var = Variable( torch.Tensor((value,) ) )\n",
    "            if(self.use_gpu):\n",
    "                ret_var = ret_var.cuda()\n",
    "            return ret_var\n",
    "\n",
    "class DSSIM(FakeNet):\n",
    "\n",
    "    def forward(self, in0, in1, retPerLayer=None):\n",
    "        assert(in0.size()[0]==1) # currently only supports batchSize 1\n",
    "\n",
    "        if(self.colorspace=='RGB'):\n",
    "            value = dssim(1.*tensor2im(in0.data), 1.*tensor2im(in1.data), range=255.).astype('float')\n",
    "        elif(self.colorspace=='Lab'):\n",
    "            value = dssim(tensor2np(tensor2tensorlab(in0.data,to_norm=False)), \n",
    "                tensor2np(tensor2tensorlab(in1.data,to_norm=False)), range=100.).astype('float')\n",
    "        ret_var = Variable( torch.Tensor((value,) ) )\n",
    "        if(self.use_gpu):\n",
    "            ret_var = ret_var.cuda()\n",
    "        return ret_var\n",
    "\n",
    "def print_network(net):\n",
    "    num_params = 0\n",
    "    for param in net.parameters():\n",
    "        num_params += param.numel()\n",
    "    print('Network',net)\n",
    "    print('Total number of parameters: %d' % num_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models as tv\n",
    "from collections import namedtuple\n",
    "\n",
    "y_pred = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get data 1 of 5\n",
      "x_test 1 of 5 : (14, 384, 384, 13)\n",
      "predict\n",
      "loading model\n",
      "14/14 - 11s\n",
      "y_pred : (14, 384, 384, 12)\n",
      "get data 2 of 5\n",
      "x_test 2 of 5 : (14, 384, 384, 13)\n",
      "predict\n",
      "loading model\n",
      "14/14 - 15s\n",
      "y_pred : (14, 384, 384, 12)\n",
      "get data 3 of 5\n",
      "x_test 3 of 5 : (14, 384, 384, 13)\n",
      "predict\n",
      "loading model\n",
      "14/14 - 15s\n",
      "y_pred : (14, 384, 384, 12)\n",
      "get data 4 of 5\n",
      "x_test 4 of 5 : (14, 384, 384, 13)\n",
      "predict\n",
      "loading model\n",
      "14/14 - 15s\n",
      "y_pred : (14, 384, 384, 12)\n",
      "get data 5 of 5\n",
      "x_test 5 of 5 : (14, 384, 384, 13)\n",
      "predict\n",
      "loading model\n",
      "14/14 - 16s\n",
      "y_pred : (14, 384, 384, 12)\n",
      "Setting up Perceptual loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: C:\\Users\\Swati\\Downloads\\neurips-2020-sevir-master\\notebooks\\weights\\v0.1\\alex.pth\n",
      "...[net-lin [alex]] initialized\n",
      "...Done\n",
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▉                                                                            | 1/12 [00:37<06:55, 37.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▊                                                                     | 2/12 [01:15<06:18, 37.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 3/12 [01:53<05:40, 37.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████▋                                                       | 4/12 [02:31<05:03, 37.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████▌                                                | 5/12 [03:12<04:31, 38.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 6/12 [04:04<04:16, 42.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|████████████████████████████████████████████████▍                                  | 7/12 [04:43<03:27, 41.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████▎                           | 8/12 [05:35<02:59, 44.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 9/12 [06:14<02:09, 43.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████████████▎             | 10/12 [07:07<01:31, 45.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▏      | 11/12 [07:59<00:47, 47.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running metric  ssim with thres= [255]\n",
      "Running metric  MSE with thres= 255\n",
      "Running metric  MAE with thres= 255\n",
      "Computing histogram \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [08:39<00:00, 43.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to : ../data/synrad_test_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def run_model( x_test ):\n",
    "    if args.model=='pers':\n",
    "        print('Using persistence model')\n",
    "        # only keep the data for persistence\n",
    "        x_test = x_test[...,11:12] \n",
    "        x_test = x_test*norm['scale']+norm['shift']\n",
    "        y_pred = np.concatenate(12*[x_test], axis=-1) \n",
    "        x_test = None # just to release memory ...\n",
    "        print(f'persistence data : {y_pred.shape}')\n",
    "    elif args.model=='optflow':\n",
    "        print('Using optical flow model')\n",
    "        from src.model.benchmarks import OpticalFlow\n",
    "        of=OpticalFlow()\n",
    "        y_pred=of.predict(x_test)\n",
    "        x_test = None # just to release memory ...\n",
    "        y_pred = y_pred*norm['scale']+norm['shift']\n",
    "        print(f'y_pred : {y_pred.shape}')\n",
    "    else:\n",
    "        print('loading model')\n",
    "        model = tf.keras.models.load_model(model_file,compile=False)\n",
    "        y_pred = model.predict(x_test, batch_size=16, verbose=2)\n",
    "        x_test = None # just to release memory ...\n",
    "        # scale predictions back to original scale and mean\n",
    "        if type(y_pred) == list:\n",
    "            y_pred = y_pred[0]\n",
    "        y_pred = y_pred*norm['scale']+norm['shift']\n",
    "        print(f'y_pred : {y_pred.shape}')\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def ssim(y_true,y_pred,maxVal,**kwargs):\n",
    "    yt=tf.convert_to_tensor(y_true.astype(np.uint8))\n",
    "    yp=tf.convert_to_tensor(y_pred.astype(np.uint8))\n",
    "    s=tf.image.ssim_multiscale(\n",
    "              yt, yp, max_val=maxVal[0], filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03\n",
    "    )\n",
    "    return tf.reduce_mean(s)\n",
    "\n",
    "def MAE(y_true,y_pred,dum):\n",
    "    return tf.reduce_mean(tf.keras.losses.MAE(y_true,y_pred))\n",
    "\n",
    "def MSE(y_true,y_pred,dum):\n",
    "    return tf.reduce_mean(tf.keras.losses.MSE(y_true,y_pred))\n",
    "\n",
    "def run_metric( metric, thres, y_true, y_pred, batch_size):\n",
    "    result = 0.0\n",
    "    Ltot = 0.0\n",
    "    n_batches = int(np.ceil(y_true.shape[0]/batch_size))\n",
    "    print('Running metric ',metric.__name__,'with thres=',thres)\n",
    "    for b in range(n_batches):\n",
    "        start = b*batch_size\n",
    "        end   = min((b+1)*batch_size,y_true.shape[0])\n",
    "        L = end-start\n",
    "        yt = y_true[start:end]\n",
    "        yp = y_pred[start:end]\n",
    "        result += metric(yt.astype(np.float32),yp,np.array([thres],dtype=np.float32))*L\n",
    "        Ltot+=L\n",
    "    return (result / Ltot).numpy() \n",
    "\n",
    "def run_histogram(y_true, y_pred, batch_size=1000,bins=range(255)):\n",
    "    L = len(bins)-1\n",
    "    H = np.zeros( (L,L),dtype=np.float64) \n",
    "    n_batches = int(np.ceil(y_true.shape[0]/batch_size))\n",
    "    print('Computing histogram ')\n",
    "    for b in range(n_batches):\n",
    "        start = b*batch_size\n",
    "        end   = min((b+1)*batch_size,y_true.shape[0])\n",
    "        yt = y_true[start:end]\n",
    "        yp = y_pred[start:end]\n",
    "        Hi,rb,cb = compute_histogram(yt,yp,bins)\n",
    "        H+=Hi\n",
    "    return H,rb,cb \n",
    "\n",
    "def main():\n",
    "    args = get_args()\n",
    "    model_file= \"../models/nowcast/mse_model.h5\"\n",
    "\n",
    "    test_data_file = \"../data/sample/nowcast_testing.h5\"\n",
    "\n",
    "    output_csv_file = \"../data/synrad_test_output.csv\"\n",
    "\n",
    "    SIZE=5 # spilt test data into this many chunks to avoid running out of memory\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    for i in range(SIZE):\n",
    "        #x_test, y_test, _, _ = get_data(args.test_data, end=args.num_test, pct_validation=0)\n",
    "        print(f'get data {i+1} of {SIZE}')\n",
    "        x_test_i,y_test_i = read_data(test_data_file, rank=i, size=SIZE, end=70, dtype=np.float32)\n",
    "        print(f'x_test {i+1} of {SIZE} : {x_test_i.shape}')\n",
    "        y_test_i = y_test_i*norm['scale']+norm['shift'] # unscale\n",
    "        print('predict')\n",
    "        y_pred_i = run_model( x_test_i )\n",
    "        y_test.append(y_test_i)\n",
    "        y_pred.append(y_pred_i)\n",
    "        x_test_i=None\n",
    "    y_pred = np.concatenate(y_pred,axis=0)\n",
    "    y_test = np.concatenate(y_test,axis=0)\n",
    "    y_test_i=None\n",
    "    y_pred_i=None\n",
    "    \n",
    "    \n",
    "    # calculate metrics in batches    \n",
    "    test_scores_lead = {}\n",
    "    # Loop over 12 lead times\n",
    "    model = PerceptualLoss(model='net-lin', net='alex', use_gpu=False)#True, gpu_ids=[1])\n",
    "    for lead in tqdm(range(12)):\n",
    "        test_scores={}\n",
    "        if crop > 0: \n",
    "            yt = y_test[:,crop:-crop,crop:-crop,lead:lead+1] # truth data\n",
    "            yp = y_pred[:,crop:-crop,crop:-crop,lead:lead+1] # predictions have been scaled earlier\n",
    "        else:\n",
    "            yt = y_test[...,lead:lead+1] # truth data\n",
    "            yp = y_pred[...,lead:lead+1] # predictions have been scaled earlier\n",
    "        test_scores['ssim'] = run_metric(ssim, [255], yt, yp, batch_size=32)\n",
    "        test_scores['mse'] = run_metric(MSE, 255, yt, yp, batch_size=32)\n",
    "        test_scores['mae'] = run_metric(MAE, 255, yt, yp, batch_size=32)\n",
    "        test_scores['lpips'] = get_lpips(model,yp,yt,batch_size=32,n_out=1)[0] # because this is scalar\n",
    "        \n",
    "        H,rb,cb=run_histogram(yt,yp,bins=range(255))\n",
    "        thresholds = [16,74,133,160,181,219]\n",
    "        scores = score_histogram(H,rb,cb,thresholds)\n",
    "        for t in thresholds:\n",
    "            test_scores['pod%d' % t] = scores[t]['pod']\n",
    "            test_scores['sucr%d' % t] = 1-scores[t]['far']\n",
    "            test_scores['csi%d' % t] = scores[t]['csi']\n",
    "            test_scores['bias%d' % t] = scores[t]['bias']\n",
    "        \n",
    "        test_scores_lead[lead]=test_scores\n",
    "    \n",
    "    print(f'saving to : {output_csv_file}')\n",
    "    df = pd.DataFrame({k:[v] for k,v in test_scores_lead.items()})\n",
    "    df.to_csv(output_csv_file)\n",
    "    #print('Test shape',y_test.shape,'Prediction Shape=',y_pred)\n",
    "    \n",
    "    return\n",
    "    \n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model( x_test, args ):\n",
    "    if args.model=='pers':\n",
    "        print('Using persistence model')\n",
    "        # only keep the data for persistence\n",
    "        x_test = x_test[...,11:12] \n",
    "        x_test = x_test*norm['scale']+norm['shift']\n",
    "        y_pred = np.concatenate(12*[x_test], axis=-1) \n",
    "        x_test = None # just to release memory ...\n",
    "        print(f'persistence data : {y_pred.shape}')\n",
    "    elif args.model=='optflow':\n",
    "        print('Using optical flow model')\n",
    "        from src.model.benchmarks import OpticalFlow\n",
    "        of=OpticalFlow()\n",
    "        y_pred=of.predict(x_test)\n",
    "        x_test = None # just to release memory ...\n",
    "        y_pred = y_pred*norm['scale']+norm['shift']\n",
    "        print(f'y_pred : {y_pred.shape}')\n",
    "    else:\n",
    "        print('loading model')\n",
    "        model = tf.keras.models.load_model(model_file,compile=False,custom_objects={\"tf\": tf})\n",
    "        y_pred = model.predict(x_test, batch_size=16, verbose=2)\n",
    "        x_test = None # just to release memory ...\n",
    "        # scale predictions back to original scale and mean\n",
    "        if type(y_pred) == list:\n",
    "            y_pred = y_pred[0]\n",
    "        y_pred = y_pred*norm['scale']+norm['shift']\n",
    "        print(f'y_pred : {y_pred.shape}')\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def ssim(y_true,y_pred,maxVal,**kwargs):\n",
    "    yt=tf.convert_to_tensor(y_true.astype(np.uint8))\n",
    "    yp=tf.convert_to_tensor(y_pred.astype(np.uint8))\n",
    "    s=tf.image.ssim_multiscale(\n",
    "              yt, yp, max_val=maxVal[0], filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03\n",
    "    )\n",
    "    return tf.reduce_mean(s)\n",
    "\n",
    "def MAE(y_true,y_pred,dum):\n",
    "    return tf.reduce_mean(tf.keras.losses.MAE(y_true,y_pred))\n",
    "\n",
    "def MSE(y_true,y_pred,dum):\n",
    "    return tf.reduce_mean(tf.keras.losses.MSE(y_true,y_pred))\n",
    "\n",
    "def run_metric( metric, thres, y_true, y_pred, batch_size):\n",
    "    result = 0.0\n",
    "    Ltot = 0.0\n",
    "    n_batches = int(np.ceil(y_true.shape[0]/batch_size))\n",
    "    print('Running metric ',metric.__name__,'with thres=',thres)\n",
    "    for b in range(n_batches):\n",
    "        start = b*batch_size\n",
    "        end   = min((b+1)*batch_size,y_true.shape[0])\n",
    "        L = end-start\n",
    "        yt = y_true[start:end]\n",
    "        yp = y_pred[start:end]\n",
    "        result += metric(yt.astype(np.float32),yp,np.array([thres],dtype=np.float32))*L\n",
    "        Ltot+=L\n",
    "    return (result / Ltot).numpy() \n",
    "\n",
    "def run_histogram(y_true, y_pred, batch_size=1000,bins=range(255)):\n",
    "    L = len(bins)-1\n",
    "    H = np.zeros( (L,L),dtype=np.float64) \n",
    "    n_batches = int(np.ceil(y_true.shape[0]/batch_size))\n",
    "    print('Computing histogram ')\n",
    "    for b in range(n_batches):\n",
    "        start = b*batch_size\n",
    "        end   = min((b+1)*batch_size,y_true.shape[0])\n",
    "        yt = y_true[start:end]\n",
    "        yp = y_pred[start:end]\n",
    "        Hi,rb,cb = compute_histogram(yt,yp,bins)\n",
    "        H+=Hi\n",
    "    return H,rb,cb \n",
    "\n",
    "def main():\n",
    "    #args = get_args()\n",
    "    model_file= \"../models/nowcast/mse_model.h5\"\n",
    "\n",
    "    test_data_file = \"../data/sample/nowcast_testing.h5\"\n",
    "\n",
    "    output_csv_file = \"../data/synrad_test_output.csv\"\n",
    "\n",
    "    SIZE=5 # spilt test data into this many chunks to avoid running out of memory\n",
    "    \n",
    "    for i in range(SIZE):\n",
    "        #x_test, y_test, _, _ = get_data(args.test_data, end=args.num_test, pct_validation=0)\n",
    "        print(f'get data {i+1} of {SIZE}')\n",
    "        x_test_i,y_test_i = read_data(test_data_file, rank=i, size=SIZE, end=args.num_test, dtype=np.float32)\n",
    "        print(f'x_test {i+1} of {SIZE} : {x_test_i.shape}')\n",
    "        y_test_i = y_test_i*norm['scale']+norm['shift'] # unscale\n",
    "        print('predict')\n",
    "        y_pred_i = run_model( x_test_i, args )\n",
    "        y_test.append(y_test_i)\n",
    "        y_pred.append(y_pred_i)\n",
    "        x_test_i=None\n",
    "    y_pred = np.concatenate(y_pred,axis=0)\n",
    "    y_test = np.concatenate(y_test,axis=0)\n",
    "    y_test_i=None\n",
    "    y_pred_i=None\n",
    "    \n",
    "    # calculate metrics in batches    \n",
    "    test_scores_lead = {}\n",
    "    # Loop over 12 lead times\n",
    "    model = PerceptualLoss(model='net-lin', net='alex', use_gpu=False)#True, gpu_ids=[1])\n",
    "    for lead in tqdm(range(12)):\n",
    "        test_scores={}\n",
    "        if crop > 0: \n",
    "            yt = y_test[:,crop:-crop,crop:-crop,lead:lead+1] # truth data\n",
    "            yp = y_pred[:,crop:-crop,crop:-crop,lead:lead+1] # predictions have been scaled earlier\n",
    "        else:\n",
    "            yt = y_test[...,lead:lead+1] # truth data\n",
    "            yp = y_pred[...,lead:lead+1] # predictions have been scaled earlier\n",
    "        test_scores['ssim'] = run_metric(ssim, [255], yt, yp, batch_size=32)\n",
    "        test_scores['mse'] = run_metric(MSE, 255, yt, yp, batch_size=32)\n",
    "        test_scores['mae'] = run_metric(MAE, 255, yt, yp, batch_size=32)\n",
    "        test_scores['lpips'] = get_lpips(model,yp,yt,batch_size=32,n_out=1)[0] # because this is scalar\n",
    "        \n",
    "        H,rb,cb=run_histogram(yt,yp,bins=range(255))\n",
    "        thresholds = [16,74,133,160,181,219]\n",
    "        scores = score_histogram(H,rb,cb,thresholds)\n",
    "        for t in thresholds:\n",
    "            test_scores['pod%d' % t] = scores[t]['pod']\n",
    "            test_scores['sucr%d' % t] = 1-scores[t]['far']\n",
    "            test_scores['csi%d' % t] = scores[t]['csi']\n",
    "            test_scores['bias%d' % t] = scores[t]['bias']\n",
    "        \n",
    "        test_scores_lead[lead]=test_scores\n",
    "    \n",
    "    print(f'saving to : {output_csv_file}')\n",
    "    df = pd.DataFrame({k:[v] for k,v in test_scores_lead.items()})\n",
    "    df.to_csv(output_csv_file)\n",
    "    \n",
    "    return\n",
    "    \n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-3aaf935e6aec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
